{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mining-Opinions-to-Predict-Customer-Trends-using-Transformers-PyTorch",
      "provenance": [],
      "collapsed_sections": [
        "zchVIJkXTC9E",
        "E1gFSLa-vZDY"
      ],
      "machine_shape": "hm",
      "mount_file_id": "1TqblcmiKjFQ93Nx6tL-CiMuNxALslWmn",
      "authorship_tag": "ABX9TyN6wrBR7vKG4BkvfPKMxM1d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a754583878a4102ae2601b78be056a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a7a008eb44d344c8b6d88d470d5d39e0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_358ad862b6094be5a384239f6dfd1b56",
              "IPY_MODEL_b89940f0e7dc4829b4e8f344c343c0b5"
            ]
          }
        },
        "a7a008eb44d344c8b6d88d470d5d39e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "358ad862b6094be5a384239f6dfd1b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cfa2e3e11042493b94b27e3f5363238a",
            "_dom_classes": [],
            "description": "Processing 3000 examples on 4 cores: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ceef15eb9b1a4abfb0fe27c58921d0fc"
          }
        },
        "b89940f0e7dc4829b4e8f344c343c0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99a431f9650c4c7d9df10d21ab24b519",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3000/3000 [00:03&lt;00:00, 789.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_265fd0fdd13e4529ac12ac87512fd79a"
          }
        },
        "cfa2e3e11042493b94b27e3f5363238a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ceef15eb9b1a4abfb0fe27c58921d0fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99a431f9650c4c7d9df10d21ab24b519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "265fd0fdd13e4529ac12ac87512fd79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4af8308790f34204a625958fd2138be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_296f0d5128f74b2b9dc7e6687a9f52d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_60bace1a5ec54430856f9c1573fc90d4",
              "IPY_MODEL_8bf0ee59ec30433ca91631affb8cc6c4"
            ]
          }
        },
        "296f0d5128f74b2b9dc7e6687a9f52d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60bace1a5ec54430856f9c1573fc90d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1818ad7672614194821311afcb65eeff",
            "_dom_classes": [],
            "description": "Processing 300 examples on 4 cores: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 300,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fd31fb7bd864c42b80c8a77d9a3a814"
          }
        },
        "8bf0ee59ec30433ca91631affb8cc6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_720dd7f9b1b14a6bbae6314e11310624",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 300/300 [00:12&lt;00:00, 23.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8259f63ca28476d8d60ff1ce89f0410"
          }
        },
        "1818ad7672614194821311afcb65eeff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fd31fb7bd864c42b80c8a77d9a3a814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "720dd7f9b1b14a6bbae6314e11310624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8259f63ca28476d8d60ff1ce89f0410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ad17ce535344e57a0c4e0e6c28444aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e581071db3204a51954d3a7b4c4e75ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_33bb22a2d6e94ef5bfab2aea92db6625",
              "IPY_MODEL_95ae5c5de09e437fb4093e968e56e6ec"
            ]
          }
        },
        "e581071db3204a51954d3a7b4c4e75ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33bb22a2d6e94ef5bfab2aea92db6625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6155d1faf32c45cdabf27c8f57f6af54",
            "_dom_classes": [],
            "description": "Epoch [1/5]: [85/85] 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 85,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e18e118c5eab44b9a38e46bc0df4fc27"
          }
        },
        "95ae5c5de09e437fb4093e968e56e6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50f7741977384b10aa8a77576567f122",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", loss=0.173 [02:04&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3e249a4fbf244788f28e7588a10198d"
          }
        },
        "6155d1faf32c45cdabf27c8f57f6af54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e18e118c5eab44b9a38e46bc0df4fc27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50f7741977384b10aa8a77576567f122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3e249a4fbf244788f28e7588a10198d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09a9c50474174979ab12c942a450a9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b111973ebd54bcfb16d674d9ed4ef62",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f453bf7d06144bfbd5335c710414dfd",
              "IPY_MODEL_8ce095e4a050443aaf426f1e540a1ceb"
            ]
          }
        },
        "9b111973ebd54bcfb16d674d9ed4ef62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f453bf7d06144bfbd5335c710414dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2cac56cb06ff40c7ad49d4429cbef7a3",
            "_dom_classes": [],
            "description": "Epoch [2/5]: [85/85] 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 85,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5dd0d08c71844ce92b09d10dd1f8d26"
          }
        },
        "8ce095e4a050443aaf426f1e540a1ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_354427530c0e42b89f2b52968b5dc46f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", loss=0 [00:23&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b639814187db472e8720daa9b935dfe4"
          }
        },
        "2cac56cb06ff40c7ad49d4429cbef7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5dd0d08c71844ce92b09d10dd1f8d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "354427530c0e42b89f2b52968b5dc46f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b639814187db472e8720daa9b935dfe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1098dda308c44c9fa3b16a54ce528510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_54a4079e29e8465fad0fb5959940bffa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e123a1b50851455591002914526de4e8",
              "IPY_MODEL_41f7e5ff3c42459f93d3c352eae21579"
            ]
          }
        },
        "54a4079e29e8465fad0fb5959940bffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e123a1b50851455591002914526de4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ecebeba13786436ebec9dc829b0503c8",
            "_dom_classes": [],
            "description": "Epoch [3/5]: [85/85] 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 85,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e1f69ec2ad543e5bbef099af5772b6a"
          }
        },
        "41f7e5ff3c42459f93d3c352eae21579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d14ffb800f2e4930a438eb79f21daed6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", loss=0 [00:23&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48c1868672944db68fb1f139cf53c2a2"
          }
        },
        "ecebeba13786436ebec9dc829b0503c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e1f69ec2ad543e5bbef099af5772b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d14ffb800f2e4930a438eb79f21daed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48c1868672944db68fb1f139cf53c2a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c06754ad7d7d4d6e95bee67e3fb34aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c13e26ba30f4c048e4c0340f10a309c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0addd13ea02b41a8a0145588f7bb8dc6",
              "IPY_MODEL_02e428f09a4747f586d375542571db74"
            ]
          }
        },
        "0c13e26ba30f4c048e4c0340f10a309c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0addd13ea02b41a8a0145588f7bb8dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_757157b2f41a4f20a40904dd9cab99a2",
            "_dom_classes": [],
            "description": "Epoch [4/5]: [85/85] 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 85,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_165f9f2cac02483ba4e1a4cd36f12ef6"
          }
        },
        "02e428f09a4747f586d375542571db74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ece1947b57fc4d7a9474edb617418d71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", loss=0 [00:23&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5d68c6b86c041d8bc29114b8e183ec8"
          }
        },
        "757157b2f41a4f20a40904dd9cab99a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "165f9f2cac02483ba4e1a4cd36f12ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ece1947b57fc4d7a9474edb617418d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5d68c6b86c041d8bc29114b8e183ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6811767fe9ee45a98086d91ef377b3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a91390a16f2c401f8815f34df1379702",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9141a9bc3c54d4695f4525d4d0c508d",
              "IPY_MODEL_09bde49902974916913e1466f6c9d983"
            ]
          }
        },
        "a91390a16f2c401f8815f34df1379702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9141a9bc3c54d4695f4525d4d0c508d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04a3593d35ae4e4fb20d0e8240f4ea04",
            "_dom_classes": [],
            "description": "Epoch [5/5]: [85/85] 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 85,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d1f99f2067f44d48bde1da7e41bca8e"
          }
        },
        "09bde49902974916913e1466f6c9d983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8bede390caf748258015e0b95b6d8360",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", loss=0 [00:23&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aff420f3fdfb4ed7913abcae7000a251"
          }
        },
        "04a3593d35ae4e4fb20d0e8240f4ea04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d1f99f2067f44d48bde1da7e41bca8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bede390caf748258015e0b95b6d8360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aff420f3fdfb4ed7913abcae7000a251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VidushiBhatia/Mining-Opinions-using-Transformers-PyTorch/blob/main/Mining_Opinions_to_Predict_Customer_Trends_using_Transformers_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxI_zCTVXAmJ"
      },
      "source": [
        "# ***Mining Opinions to Predict Customer Trends*** <br> *(Transfer Learning and Fine Tuning of Transformers in PyTorch)*\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVcMfKwXTOjg"
      },
      "source": [
        "### Overview\n",
        "\n",
        "* **Objective**: Observe trends in change of opinions / interest of customers for different product types across time. At brand level, can also be used for brand value monitoring and competitor analysis.\n",
        "\n",
        "* **Dataset used**: 'Unprocessed' tar file from [Multi-Domain Sentiment Dataset (version 2.0)](https://www.cs.jhu.edu/~mdredze/datasets/sentiment/)\n",
        "\n",
        "* **Output**: [Add dashboard image]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJKmSS6r64ma"
      },
      "source": [
        "### 1 - Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqDU7OcbI7RV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa8732c-f2bf-4c66-86ce-f849c95d2cc6"
      },
      "source": [
        "# Install for using ignite\n",
        "!pip install torch==1.8.1 pytorch-transformers pytorch-ignite"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/74/6fc9dee50f7c93d6b7d9644554bdc9692f3023fa5d1de779666e6bf8ae76/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 804.1MB 15kB/s \n",
            "\u001b[?25hCollecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184kB 43.9MB/s \n",
            "\u001b[?25hCollecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/c3/f472843797b5ccbb2f0e806a6927f52c7c9522bfcea8e7e881d39258368b/pytorch_ignite-0.4.5-py3-none-any.whl (221kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225kB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.41.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/e1/2c6c374f043c3f22829563b7fb2bf28fe3dca7ce5994bc5ceeff0959d6c9/boto3-1.17.105-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 58.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.105\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/da/3417300f85ba5173e8dba9248b9ae8bcb74a8aac1c92fa3d257f99073b9e/botocore-1.20.105-py2.py3-none-any.whl (7.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.7MB 53.9MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.105->boto3->pytorch-transformers) (2.8.1)\n",
            "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.105 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, sacremoses, sentencepiece, jmespath, botocore, s3transfer, boto3, pytorch-transformers, pytorch-ignite\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "Successfully installed boto3-1.17.105 botocore-1.20.105 jmespath-0.10.0 pytorch-ignite-0.4.5 pytorch-transformers-1.2.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.96 torch-1.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEd1F-E26-Me"
      },
      "source": [
        "import os                                        # allows to interact with the underlying operating system, access directories and update paths\n",
        "import tarfile                                   # the input dataset is a tar file, this package helps in reading it\n",
        "from bs4 import BeautifulSoup                    # the tar files contain XML datasets, this package helps pulling and manipulating that data\n",
        "import pandas as pd                              # helps in creating dataframes from the input data\n",
        "import regex as re                               # for text processing\n",
        "import string                                    # for text processing\n",
        "import numpy as np                               # for using numpy arrays\n",
        "\n",
        "# Relevant torch packages for transfer learning and fine tuning \n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
        "from pytorch_transformers import BertTokenizer\n",
        "from pytorch_transformers.optimization import AdamW\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.metrics import RunningAverage, Accuracy \n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from ignite.contrib.handlers import CosineAnnealingScheduler, PiecewiseLinear, create_lr_scheduler_with_warmup, ProgressBar\n",
        "from pytorch_transformers import cached_path\n",
        "\n",
        "# Data structures\n",
        "from collections import namedtuple\n",
        "from typing import Tuple\n",
        "\n",
        "# Other packages for parallel processing\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "from tqdm.notebook import tqdm                   # for progress bars\n",
        "from itertools import repeat                     # creates memory space for one variable and repeats iterations using that variable\n",
        "# from tqdm import tqdm\n",
        "# import warnings\n",
        "\n",
        "import ipywidgets\n",
        "from IPython.display import display, clear_output\n",
        "from ipywidgets import Layout\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d23cjNrDIrJi",
        "outputId": "4fa32350-4b0b-4061-98bd-9150841d4e4c"
      },
      "source": [
        "# Check if GPU is running\n",
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul  6 06:51:54 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py64E4jm7tnI"
      },
      "source": [
        "### 2 - Load XML to a Dataframe\n",
        "\n",
        "The dataset used for this notebook has multiple positive and negative review files compressed into a tar format. To get a dataframe with x and y values (text and sentiment labels respectively), we need to execute the following:\n",
        "1. Extract relevant files from tar\n",
        "2. Covert XML tree into a dataframe for relevant elements\n",
        "3. Create a train and test set with processed x and y values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0xk-ASM8jMj",
        "outputId": "162c95cd-da7a-486f-f8f3-0d57310d6dd8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BZxLgVDUX6b"
      },
      "source": [
        "# Helper Function 1: Extract XML data from tar files\n",
        "def ExtractContent(path):\n",
        "  tar = tarfile.open(path,'r' )\n",
        "  \n",
        "  # Find relevant file names\n",
        "  files = [name for name in tar.getnames()]\n",
        "  pos_files = []\n",
        "  neg_files = []\n",
        "  for file in files:\n",
        "    if file.endswith('positive.review'): \n",
        "      pos_files.append(file)\n",
        "    if file.endswith('negative.review'):\n",
        "      neg_files.append(file)\n",
        "\n",
        "  # Extract Positive and Negative reviews\n",
        "  pos_content = []\n",
        "  for file in pos_files:\n",
        "    extracted_file = tar.extractfile(file)\n",
        "    content = extracted_file.read()\n",
        "    pos_content.append(content)\n",
        "\n",
        "  neg_content = []\n",
        "  for file in neg_files:\n",
        "    extracted_file = tar.extractfile(file)\n",
        "    content = extracted_file.read()\n",
        "    neg_content.append(content)\n",
        "  return pos_content, neg_content"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQLfztLSmrR0"
      },
      "source": [
        "# Helper Function 2: Create a dataframe from XML file\n",
        "def CreateDF(content_list):\n",
        "  # Check the exhaustive list of elements with soup.find_all() and create a dataframe with only relevant columns\n",
        "  # columns = ['unique_id','asin','product_name','product_type','helpful','rating','title','date','reviewer','reviewer_location','review_text']\n",
        "\n",
        "  columns = ['product_type','rating','date','title','review_text']     # only processing relevant columns\n",
        "  interim_df = []\n",
        "  for idx, item in enumerate(content_list):      # iterate over positive and negative file-list\n",
        "    for content in item:                         # iterate over all extracted files\n",
        "      bs_content = BeautifulSoup(content, 'lxml')\n",
        "      table_rows = bs_content.find_all(\"review\") # create rows from the root element\n",
        "      df = pd.DataFrame()\n",
        "      for c in columns:                          # add corresponding columns to the created dataframe\n",
        "        values = bs_content.find_all(c)\n",
        "        if len(values)!=len(table_rows):         # in case the size of each element is not equal\n",
        "          col = []\n",
        "          for t in table_rows:\n",
        "            row_val = t.find_all(c)\n",
        "            row = [t.text.strip() for t in row_val]\n",
        "            col.append(row[0])\n",
        "        else:\n",
        "          col = [t.text.strip() for t in values]\n",
        "        df[c] = col\n",
        "      interim_df.append(df)\n",
        "  output = pd.concat(interim_df)                # create a master df with all positive, negative reviews\n",
        "  return output"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjX9JhBGmFjc"
      },
      "source": [
        "# LOAD DATA USING HELPER FUNCTIONS\n",
        "\n",
        "# STEP 1 - Extract relevant content from tar file\n",
        "path = '/content/drive/My Drive/NLP - Sentiment Analysis & Keyword Extraction/unprocessed.tar.gz'\n",
        "pos_content, neg_content = ExtractContent(path)\n",
        "\n",
        "# STEP 2 - Convert relevant elements of XML to dataframe \n",
        "content_list = [pos_content, neg_content]\n",
        "master_df = CreateDF(content_list)\n",
        "\n",
        "# STEP 3 - Create train, test dataset with x (i.e. text) and y (i.e. labels)\n",
        "master_df['label'] = (pd.to_numeric(master_df['rating'])>3)*1  # ratings >3 are labeled as positive sentiment\n",
        "master_df['text'] =  master_df['title'].str.cat(master_df['review_text'], sep=' ', na_rep='?') \n",
        "master_df['text'] = master_df['text'].replace(r\" +\",\" \",regex = True) # remove whitespaces\n",
        "temp_mask = np.random.rand(len(master_df)) < 0.7   # 70% data is train set\n",
        "train_set = master_df[temp_mask]\n",
        "test_set  = master_df[~temp_mask]\n",
        "train_set = train_set.drop(['rating','title','review_text'], axis='columns') # retain only processed columns\n",
        "test_set = test_set.drop(['rating','title','review_text'], axis='columns')\n",
        "\n",
        "# n = np.floor(len(train_set)*90%) \n",
        "# sample = train_set[n:len(train_set)]\n",
        "# train_set = train_set[0:n]\n",
        "# print(\"len of master df: \", len(master_df), \"\\nlen of train set: \",len(train_set), \"\\nlen of test set: \",len(test_set), \"\\nlen of sample: \",len(sample))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVJbCcHmesX8"
      },
      "source": [
        "train_set = train_set[0:3000]\n",
        "test_set = test_set[0:300] "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWg5UsDulEQX",
        "outputId": "0dda23cd-9cec-4efb-a12d-0a67fa9ba46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "train_set = train_set.drop(['product_type','date'], axis='columns')\n",
        "test_set = test_set.drop(['product_type','date'], axis='columns')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Recomend I covered a similar theme in my inter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>Memento (Limited Edition) DVD This is a great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>How To Use Your Body Language To Win Friends A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>Ironic humor This film can be interpreted any ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>Best In Show is Best in Comedy This movie is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>1</td>\n",
              "      <td>superb Very good movie. Great acting &amp; plot. V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>1</td>\n",
              "      <td>An Intelligent and Captivating Psychological T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>1</td>\n",
              "      <td>Jackie Chan in all his glory While the dubbing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>1</td>\n",
              "      <td>Scooby Sports!!!! This DVD is way cool with a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1</td>\n",
              "      <td>Reviewing the White Sox 2005 World Series Vide...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                               text\n",
              "1        1  Recomend I covered a similar theme in my inter...\n",
              "5        1  Memento (Limited Edition) DVD This is a great ...\n",
              "7        1  How To Use Your Body Language To Win Friends A...\n",
              "8        1  Ironic humor This film can be interpreted any ...\n",
              "10       1  Best In Show is Best in Comedy This movie is a...\n",
              "..     ...                                                ...\n",
              "987      1  superb Very good movie. Great acting & plot. V...\n",
              "988      1  An Intelligent and Captivating Psychological T...\n",
              "989      1  Jackie Chan in all his glory While the dubbing...\n",
              "991      1  Scooby Sports!!!! This DVD is way cool with a ...\n",
              "996      1  Reviewing the White Sox 2005 World Series Vide...\n",
              "\n",
              "[300 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zchVIJkXTC9E"
      },
      "source": [
        "### 3 - Tokenize Representations\n",
        "\n",
        "The neural network model would require word representations to read the text. To execute this, we will define a text processing module which will take \"text\" as input and return \"sequences of integers\".\n",
        "\n",
        "To convert text to this \"id\", there are multiple vocabularies available. In this notebook, we'll use `pytorch-transformersâ€™s BertTokenizer` for tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4hjR_WjhWzo"
      },
      "source": [
        "class TextProcessing:\n",
        "    CLS = '[CLS]'                                                 # Special token for sentence classification\n",
        "    PAD = '[PAD]'                                                 # Special token for padding\n",
        "    def __init__(self, tokenizer, num_max_positions:int=512):\n",
        "        self.tokenizer=tokenizer\n",
        "        self.num_max_positions = num_max_positions\n",
        "    \n",
        "    def process_example(self, example: Tuple[int, str]):          # function to convert text strings into tokens of equal length\n",
        "        label, text = example[0], example[1]\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        \n",
        "        if len(tokens) >= self.num_max_positions:                 # shorten the token length is it is longer than max_positions\n",
        "            tokens = tokens[:self.num_max_positions-1] \n",
        "            ids =  self.tokenizer.convert_tokens_to_ids(tokens) + [self.tokenizer.vocab[self.CLS]]\n",
        "        else:                                                     # pad to ensure that all token arrays are of same length\n",
        "            pad = [self.tokenizer.vocab[self.PAD]] * (self.num_max_positions-len(tokens)-1)\n",
        "            ids = self.tokenizer.convert_tokens_to_ids(tokens) + [self.tokenizer.vocab[self.CLS]] + pad\n",
        "        \n",
        "        return np.array(ids, dtype='int64'), int(label)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fITdHhrv0FM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a55e160-1715-47a3-ae42-c1d9a46d6d8a"
      },
      "source": [
        "NUM_MAX_POSITIONS = 256 \n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# import the 'bert-base-cased' tokenizer from PyTorch\n",
        "from pytorch_transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
        "\n",
        "# Initialize a processor with the imported tokenizer and TextProcessing class\n",
        "processor = TextProcessing(tokenizer, num_max_positions=NUM_MAX_POSITIONS)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213450/213450 [00:00<00:00, 623769.70B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1gFSLa-vZDY"
      },
      "source": [
        "### 4 - Convert Dataset to DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QE9BiI9w1yD"
      },
      "source": [
        "# set the configurations for fine tuning pre-trained model to the considered dataset (incl. data loaders, parallel processing, etc.)\n",
        "LOG_DIR = \"/content/drive/My Drive/NLP - Sentiment Analysis & Keyword Extraction/logs/\"\n",
        "CACHE_DIR = \"/content/drive/My Drive/NLP - Sentiment Analysis & Keyword Extraction/cache/\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "FineTuningConfig = namedtuple('FineTuningConfig',\n",
        "      field_names=\"num_classes, dropout, init_range, batch_size, lr, max_norm, n_epochs,\"\n",
        "                  \"n_warmup, valid_pct, gradient_acc_steps, device, log_dir\")\n",
        "\n",
        "finetuning_config = FineTuningConfig(\n",
        "                2, 0.1, 0.02, BATCH_SIZE, 6.5e-5, 1.0, 2,10, 0.1, 1, device, LOG_DIR)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy2pKWp3xJmY"
      },
      "source": [
        "# Function to process rows using the text processing class defined earlier\n",
        "def process_row(processor, row):\n",
        "    return processor.process_example((row[1]['label'], row[1]['text']))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3_TS4YiV5Gf"
      },
      "source": [
        "# Function to convert dataframe into DataLoader after processing with the BERT tokenizer using process_row function\n",
        "def create_dataloader(df: pd.DataFrame,\n",
        "                      processor: TextProcessing,\n",
        "                      batch_size: int = 32,\n",
        "                      valid_pct: float = None):\n",
        "    \n",
        "    # to enable multiprocessing\n",
        "    with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
        "        result = list(\n",
        "            tqdm(executor.map(process_row,\n",
        "                              repeat(processor),\n",
        "                              df.iterrows(),\n",
        "                              chunksize=len(df) // 10),\n",
        "                 desc=f\"Processing {len(df)} examples on {num_cores} cores\",\n",
        "                 total=len(df)))\n",
        "\n",
        "    features = [r[0] for r in result]\n",
        "    labels = [r[1] for r in result]\n",
        "\n",
        "    # Compile features and labels to form the dataset\n",
        "    dataset = TensorDataset(torch.tensor(features, dtype=torch.long),\n",
        "                            torch.tensor(labels, dtype=torch.long))\n",
        "\n",
        "    # define train set and valid set based on defined valid percentage in fine tuning configuration\n",
        "    if valid_pct is not None:\n",
        "        valid_size = int(valid_pct * len(df))\n",
        "        train_size = len(df) - valid_size\n",
        "        valid_dataset, train_dataset = random_split(dataset,\n",
        "                                                    [valid_size, train_size])\n",
        "        valid_loader = DataLoader(valid_dataset,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=False)\n",
        "        train_loader = DataLoader(train_dataset,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=False)\n",
        "        return train_loader, valid_loader\n",
        "\n",
        "    data_loader = DataLoader(dataset,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=False)\n",
        "    return data_loader"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "8a754583878a4102ae2601b78be056a1",
            "a7a008eb44d344c8b6d88d470d5d39e0",
            "358ad862b6094be5a384239f6dfd1b56",
            "b89940f0e7dc4829b4e8f344c343c0b5",
            "cfa2e3e11042493b94b27e3f5363238a",
            "ceef15eb9b1a4abfb0fe27c58921d0fc",
            "99a431f9650c4c7d9df10d21ab24b519",
            "265fd0fdd13e4529ac12ac87512fd79a",
            "4af8308790f34204a625958fd2138be2",
            "296f0d5128f74b2b9dc7e6687a9f52d0",
            "60bace1a5ec54430856f9c1573fc90d4",
            "8bf0ee59ec30433ca91631affb8cc6c4",
            "1818ad7672614194821311afcb65eeff",
            "7fd31fb7bd864c42b80c8a77d9a3a814",
            "720dd7f9b1b14a6bbae6314e11310624",
            "e8259f63ca28476d8d60ff1ce89f0410"
          ]
        },
        "id": "wHCNMoL4Y4oM",
        "outputId": "91ebf9b6-ef24-4598-897b-f51462970579"
      },
      "source": [
        "# create train and valid sets by splitting\n",
        "num_cores = cpu_count()  # for parallel processing\n",
        "train_dl, valid_dl = create_dataloader(train_set, processor, \n",
        "                                    batch_size=finetuning_config.batch_size, \n",
        "                                    valid_pct=finetuning_config.valid_pct)\n",
        "\n",
        "test_dl = create_dataloader(test_set, processor, \n",
        "                             batch_size=finetuning_config.batch_size, \n",
        "                             valid_pct=None)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a754583878a4102ae2601b78be056a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Processing 3000 examples on 4 cores', max=3000.0, style=Pâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4af8308790f34204a625958fd2138be2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Processing 300 examples on 4 cores', max=300.0, style=Proâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbL1SLp0wbdT"
      },
      "source": [
        "### 5 - Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcHKpuBNyipi"
      },
      "source": [
        "# Adopted from HuggingFace's Transfer Learning tutorial\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_dim, num_embeddings, num_max_positions, num_heads, num_layers, dropout, causal):\n",
        "        super().__init__()\n",
        "        self.causal = causal\n",
        "        self.tokens_embeddings = nn.Embedding(num_embeddings, embed_dim)\n",
        "        self.position_embeddings = nn.Embedding(num_max_positions, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.attentions, self.feed_forwards = nn.ModuleList(), nn.ModuleList()\n",
        "        self.layer_norms_1, self.layer_norms_2 = nn.ModuleList(), nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.attentions.append(nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout))\n",
        "            self.feed_forwards.append(nn.Sequential(nn.Linear(embed_dim, hidden_dim),\n",
        "                                                    nn.ReLU(),\n",
        "                                                    nn.Linear(hidden_dim, embed_dim)))\n",
        "            self.layer_norms_1.append(nn.LayerNorm(embed_dim, eps=1e-12))\n",
        "            self.layer_norms_2.append(nn.LayerNorm(embed_dim, eps=1e-12))\n",
        "\n",
        "    def forward(self, x, padding_mask=None):\n",
        "        positions = torch.arange(len(x), device=x.device).unsqueeze(-1)\n",
        "        h = self.tokens_embeddings(x)\n",
        "        h = h + self.position_embeddings(positions).expand_as(h)\n",
        "        h = self.dropout(h)\n",
        "\n",
        "        attn_mask = None\n",
        "        if self.causal:\n",
        "            attn_mask = torch.full((len(x), len(x)), -float('Inf'), device=h.device, dtype=h.dtype)\n",
        "            attn_mask = torch.triu(attn_mask, diagonal=1)\n",
        "\n",
        "        for layer_norm_1, attention, layer_norm_2, feed_forward in zip(self.layer_norms_1, self.attentions,\n",
        "                                                                       self.layer_norms_2, self.feed_forwards):\n",
        "            h = layer_norm_1(h)\n",
        "            x, _ = attention(h, h, h, attn_mask=attn_mask, need_weights=False, key_padding_mask=padding_mask)\n",
        "            x = self.dropout(x)\n",
        "            h = x + h\n",
        "\n",
        "            h = layer_norm_2(h)\n",
        "            x = feed_forward(h)\n",
        "            x = self.dropout(x)\n",
        "            h = x + h\n",
        "        return h"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbsmDpSuXJbG"
      },
      "source": [
        "# Adopted from HuggingFace's Transfer Learning tutorial\n",
        "class TransformerWithClfHead(nn.Module):\n",
        "    def __init__(self, config, fine_tuning_config):\n",
        "        super().__init__()\n",
        "        self.config = fine_tuning_config\n",
        "        self.transformer = Transformer(config.embed_dim, config.hidden_dim, config.num_embeddings,\n",
        "                                       config.num_max_positions, config.num_heads, config.num_layers,\n",
        "                                       fine_tuning_config.dropout, causal=not config.mlm)\n",
        "        self.classification_head = nn.Linear(config.embed_dim, fine_tuning_config.num_classes)\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding, nn.LayerNorm)):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.init_range)\n",
        "        if isinstance(module, (nn.Linear, nn.LayerNorm)) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, clf_tokens_mask, clf_labels=None, padding_mask=None):\n",
        "        hidden_states = self.transformer(x, padding_mask)\n",
        "\n",
        "        clf_tokens_states = (hidden_states * clf_tokens_mask.unsqueeze(-1).float()).sum(dim=0)\n",
        "        clf_logits = self.classification_head(clf_tokens_states)\n",
        "\n",
        "        if clf_labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "            loss = loss_fct(clf_logits.view(-1, clf_logits.size(-1)), clf_labels.view(-1))\n",
        "            return clf_logits, loss\n",
        "        return clf_logits"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOsBaiiny8o0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c90e98a-5c0a-4f2b-a183-ddf0298d504a"
      },
      "source": [
        "# download pre-trained model and config\n",
        "state_dict = torch.load(cached_path(\"https://s3.amazonaws.com/models.huggingface.co/\"\n",
        "                                    \"naacl-2019-tutorial/model_checkpoint.pth\"), map_location='cpu')\n",
        "\n",
        "config = torch.load(cached_path(\"https://s3.amazonaws.com/models.huggingface.co/\"\n",
        "                                        \"naacl-2019-tutorial/model_training_args.bin\"))\n",
        "\n",
        "# init model: Transformer base + classifier head\n",
        "model = TransformerWithClfHead(config=config, fine_tuning_config=finetuning_config).to(finetuning_config.device)\n",
        "\n",
        "incompatible_keys = model.load_state_dict(state_dict, strict=False)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201626725/201626725 [00:07<00:00, 26164536.14B/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 837/837 [00:00<00:00, 317273.61B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT-gcirBv65r"
      },
      "source": [
        "### 6 - Model Fine Tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jmOPlpmi5OX"
      },
      "source": [
        "def update(engine, batch):\n",
        "    \"update function for training\"\n",
        "    model.train()\n",
        "    inputs, labels = (t.to(finetuning_config.device) for t in batch)\n",
        "    inputs = inputs.transpose(0, 1).contiguous() # [S, B]\n",
        "    _, loss = model(inputs, \n",
        "                    clf_tokens_mask = (inputs == tokenizer.vocab[processor.CLS]), \n",
        "                    clf_labels=labels)\n",
        "    loss = loss / finetuning_config.gradient_acc_steps\n",
        "    loss.backward()\n",
        "    \n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), finetuning_config.max_norm)\n",
        "    if engine.state.iteration % finetuning_config.gradient_acc_steps == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    return loss.item()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k0_5VkLi63d"
      },
      "source": [
        "def inference(engine, batch):\n",
        "    \"update function for evaluation\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        batch, labels = (t.to(finetuning_config.device) for t in batch)\n",
        "        inputs = batch.transpose(0, 1).contiguous()\n",
        "        logits = model(inputs,\n",
        "                       clf_tokens_mask = (inputs == tokenizer.vocab[processor.CLS]),\n",
        "                       padding_mask = (batch == tokenizer.vocab[processor.PAD]))\n",
        "    return logits, labels"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIVXGHc2i_1x"
      },
      "source": [
        "def predict(model, tokenizer, int2label, input=\"test\"):\n",
        "    \"predict sentiment using model\"\n",
        "    tok = tokenizer.tokenize(input)\n",
        "    if len(tok) >= NUM_MAX_POSITIONS:                 # shorten the token length is it is longer than max_positions\n",
        "      tok = tok[:NUM_MAX_POSITIONS-1]         \n",
        "    ids = tokenizer.convert_tokens_to_ids(tok) + [tokenizer.vocab['[CLS]']]\n",
        "    tensor = torch.tensor(ids, dtype=torch.long)\n",
        "    tensor = tensor.to(device)\n",
        "    tensor = tensor.reshape(1, -1)\n",
        "    tensor_in = tensor.transpose(0, 1).contiguous() # [S, 1]\n",
        "    logits = model(tensor_in,\n",
        "                   clf_tokens_mask = (tensor_in == tokenizer.vocab['[CLS]']),\n",
        "                   padding_mask = (tensor == tokenizer.vocab['[PAD]']))\n",
        "    val, _ = torch.max(logits, 0)\n",
        "    val = F.softmax(val, dim=0).detach().cpu().numpy()    \n",
        "    return {int2label[val.argmax()]: val.max(),\n",
        "            int2label[val.argmin()]: val.min()}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iElb48MOHWlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e44ad2-6afb-4f95-be0c-a3f53726c42e"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=finetuning_config.lr, correct_bias=False) \n",
        "\n",
        "trainer = Engine(update)\n",
        "evaluator = Engine(inference)\n",
        "\n",
        "# add metric to evaluator \n",
        "Accuracy().attach(evaluator, \"accuracy\")\n",
        "\n",
        "# add evaluator to trainer: eval on valid set after each epoch\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_validation_results(engine):\n",
        "    evaluator.run(valid_dl)\n",
        "    print(f\"validation epoch: {engine.state.epoch} acc: {100*evaluator.state.metrics['accuracy']}\")\n",
        "          \n",
        "# lr schedule: linearly warm-up to lr and then to zero\n",
        "scheduler = PiecewiseLinear(optimizer, 'lr', [(0, 0.0), (finetuning_config.n_warmup, finetuning_config.lr),\n",
        "                                              (len(train_dl)*finetuning_config.n_epochs, 0.0)])\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "\n",
        "\n",
        "# add progressbar with loss\n",
        "RunningAverage(output_transform=lambda x: x).attach(trainer, \"loss\")\n",
        "ProgressBar(persist=True).attach(trainer, metric_names=['loss'])\n",
        "\n",
        "# save checkpoints and finetuning config\n",
        "checkpoint_handler = ModelCheckpoint(finetuning_config.log_dir, 'finetuning_checkpoint', \n",
        "                                     save_interval=1, require_empty=False)\n",
        "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler, {'imdb_model': model})\n",
        "\n",
        "int2label = {0: 'negative', 1: 'positive'}\n",
        "\n",
        "# save metadata\n",
        "torch.save({\n",
        "    \"config\": config,\n",
        "    \"config_ft\": finetuning_config,\n",
        "    \"int2label\": int2label\n",
        "}, os.path.join(finetuning_config.log_dir, \"metadata.bin\"))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ignite/handlers/checkpoint.py:825: UserWarning: Argument save_interval is deprecated and should be None. This argument will be removed in 0.5.0.Please, use events filtering instead, e.g. Events.ITERATION_STARTED(every=1000)\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429,
          "referenced_widgets": [
            "6ad17ce535344e57a0c4e0e6c28444aa",
            "e581071db3204a51954d3a7b4c4e75ab",
            "33bb22a2d6e94ef5bfab2aea92db6625",
            "95ae5c5de09e437fb4093e968e56e6ec",
            "6155d1faf32c45cdabf27c8f57f6af54",
            "e18e118c5eab44b9a38e46bc0df4fc27",
            "50f7741977384b10aa8a77576567f122",
            "f3e249a4fbf244788f28e7588a10198d",
            "09a9c50474174979ab12c942a450a9a6",
            "9b111973ebd54bcfb16d674d9ed4ef62",
            "8f453bf7d06144bfbd5335c710414dfd",
            "8ce095e4a050443aaf426f1e540a1ceb",
            "2cac56cb06ff40c7ad49d4429cbef7a3",
            "a5dd0d08c71844ce92b09d10dd1f8d26",
            "354427530c0e42b89f2b52968b5dc46f",
            "b639814187db472e8720daa9b935dfe4",
            "1098dda308c44c9fa3b16a54ce528510",
            "54a4079e29e8465fad0fb5959940bffa",
            "e123a1b50851455591002914526de4e8",
            "41f7e5ff3c42459f93d3c352eae21579",
            "ecebeba13786436ebec9dc829b0503c8",
            "0e1f69ec2ad543e5bbef099af5772b6a",
            "d14ffb800f2e4930a438eb79f21daed6",
            "48c1868672944db68fb1f139cf53c2a2",
            "c06754ad7d7d4d6e95bee67e3fb34aec",
            "0c13e26ba30f4c048e4c0340f10a309c",
            "0addd13ea02b41a8a0145588f7bb8dc6",
            "02e428f09a4747f586d375542571db74",
            "757157b2f41a4f20a40904dd9cab99a2",
            "165f9f2cac02483ba4e1a4cd36f12ef6",
            "ece1947b57fc4d7a9474edb617418d71",
            "a5d68c6b86c041d8bc29114b8e183ec8",
            "6811767fe9ee45a98086d91ef377b3dc",
            "a91390a16f2c401f8815f34df1379702",
            "e9141a9bc3c54d4695f4525d4d0c508d",
            "09bde49902974916913e1466f6c9d983",
            "04a3593d35ae4e4fb20d0e8240f4ea04",
            "3d1f99f2067f44d48bde1da7e41bca8e",
            "8bede390caf748258015e0b95b6d8360",
            "aff420f3fdfb4ed7913abcae7000a251"
          ]
        },
        "id": "6ne1Vc5MJ9Jk",
        "outputId": "0dadf5c0-8585-4456-b0fb-71b77fa72db6"
      },
      "source": [
        "trainer.run(train_dl, max_epochs=5)\n",
        "\n",
        "# save model weights\n",
        "torch.save(model.state_dict(), os.path.join(finetuning_config.log_dir, \"model_weights.pth\"))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ad17ce535344e57a0c4e0e6c28444aa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=85.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "validation epoch: 1 acc: 100.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09a9c50474174979ab12c942a450a9a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=85.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "validation epoch: 2 acc: 100.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1098dda308c44c9fa3b16a54ce528510",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=85.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "validation epoch: 3 acc: 100.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c06754ad7d7d4d6e95bee67e3fb34aec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=85.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "validation epoch: 4 acc: 100.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6811767fe9ee45a98086d91ef377b3dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=85.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "validation epoch: 5 acc: 100.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ6eo0b6wIGS"
      },
      "source": [
        "### 7 - Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLqWBjjNoe6s",
        "outputId": "426badec-e4aa-49c3-f38b-bdd379ea1f33"
      },
      "source": [
        "# evaluate the model on test set\n",
        "evaluator.run(test_dl)\n",
        "print(f\"Test accuracy: {100*evaluator.state.metrics['accuracy']:.3f}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 100.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dG0up8wbce"
      },
      "source": [
        "### 8 - Predict for a Real Time Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM8ntDMgoUgO",
        "outputId": "a646cd2b-5e64-4661-a36f-429470fda2f2"
      },
      "source": [
        "predict(model, tokenizer, int2label, input = \"ah! great book\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': 4.2996646e-17, 'positive': 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPRR1aWooUJF",
        "outputId": "0db5e39d-5563-45e6-a7d8-28b017f76feb"
      },
      "source": [
        "predict(model, tokenizer, int2label, input = \"I didn't enjoy the toy as muxh as I imagined\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': 6.1635914e-17, 'positive': 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iorXpzKeCM6s"
      },
      "source": [
        "### 9 - Mine Opinions for Customer Trends"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJDycFMKCLu2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "e8804107-1c31-436b-e51f-39dca5daf177"
      },
      "source": [
        "sample = master_df[0:2]\n",
        "sam_text = [\"yes, I like it\", \"no I don't\"]\n",
        "sam_long_text = [\"yes, I like it... Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\", \"no I don't\"]\n",
        "sample['prediction'] = 0\n",
        "sample['pos'] = 0\n",
        "sample['neg'] = 0\n",
        "\n",
        "for index, row in sample.iterrows():\n",
        "    output = predict(model, tokenizer, int2label, input = str(row['text']))\n",
        "    sample.loc[index, 'pos'] = output['positive']\n",
        "    sample.loc[index, 'neg'] = output['negative']\n",
        "    if output['positive'] > output['negative']:\n",
        "      sample.loc[index, 'prediction'] = output['positive']\n",
        "    else:\n",
        "      sample.loc[index, 'prediction'] = output['negative']*(-1)\n",
        "\n",
        "sample"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_type</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>review_text</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>prediction</th>\n",
              "      <th>pos</th>\n",
              "      <th>neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dvd</td>\n",
              "      <td>4.0</td>\n",
              "      <td>July 3, 2006</td>\n",
              "      <td>Excellent Fantasy, with Provisos</td>\n",
              "      <td>The story of \"Alice in Wonderland\" was controv...</td>\n",
              "      <td>1</td>\n",
              "      <td>Excellent Fantasy, with Provisos The story of ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.993048e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dvd</td>\n",
              "      <td>5.0</td>\n",
              "      <td>September 5, 2006</td>\n",
              "      <td>Recomend</td>\n",
              "      <td>I covered a similar theme in my international ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Recomend I covered a similar theme in my inter...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.804296e-17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  product_type rating               date  ... prediction  pos           neg\n",
              "0          dvd    4.0       July 3, 2006  ...        1.0  1.0  3.993048e-17\n",
              "1          dvd    5.0  September 5, 2006  ...        1.0  1.0  3.804296e-17\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_7mu-n5IUVl"
      },
      "source": [
        "# ROC curve\n",
        "# False Positive Rate = False Positives / (False Positives + True Negatives)\n",
        "# tpr = True Negatives / (True Negatives + False Positives)\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(master_df['label'], master_df['pos'])\n",
        "thresholds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPAvzrx0WpZl"
      },
      "source": [
        "# basic changes before we share the data to functions\n",
        "sample['date'] = pd.to_datetime(sample['date'], errors = 'coerce')\n",
        "sample['prediction'] = pd.to_numeric(sample['prediction']).multiply(100)\n",
        "sample = sample.sort_values(by = ['product_type', 'date'], ascending = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWSjrAVCWsdg"
      },
      "source": [
        "ALL='ALL'\n",
        "def createDropdown(array):\n",
        "  unique = array.unique().tolist()\n",
        "  unique.sort()\n",
        "  unique.insert(0,ALL)\n",
        "  return unique\n",
        "\n",
        "def CombinedEvent(year, p_type):\n",
        "  out.clear_output()\n",
        "  plot_out.clear_output()\n",
        "\n",
        "  # group by year to summarize \"ALL years\" and by month for a single year\n",
        "  if (year == ALL) & (p_type == ALL):\n",
        "    out_table = sample.groupby(sample['date'].dt.year).agg({'prediction':['count','mean']}).reset_index()\n",
        "  elif (year == ALL):\n",
        "    out_table = sample[sample['product_type']==p_type].groupby(sample['date'].dt.year).agg({'prediction':['count','mean']}).reset_index()\n",
        "  elif (p_type == ALL):\n",
        "    out_table = sample[sample['date'].dt.year==year].groupby(sample['date'].dt.strftime('%b-%Y')).agg({'prediction':['count','mean']}).reset_index()\n",
        "  else:\n",
        "    out_table = sample[(sample['date'].dt.year==year)&(sample['product_type']==p_type)].groupby(sample['date'].dt.strftime('%b-%Y')).agg({'prediction':['count','mean']}).reset_index()\n",
        "  \n",
        "  # format table summary\n",
        "  out_table.columns = out_table.columns.droplevel()\n",
        "  out_table = out_table.rename(columns = {\"\":\"Date\",\"count\":'Number of Reviews',\"mean\":'Average Sentiment'})\n",
        "\n",
        "  with out:\n",
        "    if (len(out_table)==0):\n",
        "      print (\"\\n\\nNo Data, try a different combination\\n\\n\")\n",
        "    else:\n",
        "      print(\"\\n\")\n",
        "      display(out_table)\n",
        "      print(\"\\n\\n\")\n",
        "      # plot graph\n",
        "  with plot_out:\n",
        "    if (len(out_table)==0):\n",
        "      print (\"\\n\\nNo Data, try a different combination\\n\\n\")\n",
        "    else:\n",
        "        fig, ax = plt.subplots(2,1, figsize=(15, 10))\n",
        "        ax[0].plot(out_table['Date'], out_table['Average Sentiment'], marker='o', color='orange' , label='Average Sentiment')  # Plot the chart\n",
        "        ax[0].axhline(0, c='black', ls='--')\n",
        "        ax[0].set_ylim([-100, 100])\n",
        "        ax[0].xaxis.set_visible(False)\n",
        "        ax[0].yaxis.set_major_formatter(ticker.PercentFormatter())\n",
        "        ax[0].legend()\n",
        "        ax[1].bar(out_table['Date'], out_table['Number of Reviews'], color ='maroon', width=0.15, label='Number of Reviews')\n",
        "        ax[1].yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
        "        ax[1].legend()\n",
        "        ax[1].grid(axis = 'y', color = 'grey', linestyle = '--', linewidth = 0.5)\n",
        "        plt.subplots_adjust(left=0.4,\n",
        "                            bottom=0.3, \n",
        "                            right=0.9, \n",
        "                            top=0.9, \n",
        "                            wspace=0.2, \n",
        "                            hspace=0.05)\n",
        "        plt.show()\n",
        "\n",
        "def DropdownYearEventhandler(change):\n",
        "    CombinedEvent(change.new,dropdown_categories.value)\n",
        "\n",
        "def DropdownTypeEventhandler(change):\n",
        "    CombinedEvent(dropdown_year.value,change.new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abiOK1CKWweW"
      },
      "source": [
        "out = ipywidgets.widgets.Output()\n",
        "plot_out =ipywidgets.widgets.Output()\n",
        "\n",
        "dropdown_year = ipywidgets.widgets.Dropdown(options = createDropdown(sample.date.dt.year), description = \"Year: \")\n",
        "dropdown_categories = ipywidgets.widgets.Dropdown(options = createDropdown(sample.product_type), description = \"Product Type: \")\n",
        "input_widgets = ipywidgets.widgets.HBox([dropdown_categories, dropdown_year], layout=Layout(width='60%',justify_content='space-between', margin='0 0 50px 0'))\n",
        "tab = ipywidgets.widgets.Tab([out, plot_out])\n",
        "tab.set_title(0, 'Summary Table')\n",
        "tab.set_title(1, 'Trend Chart')\n",
        "dashboard = ipywidgets.widgets.VBox([input_widgets, tab])\n",
        "\n",
        "dropdown_categories.observe(DropdownTypeEventhandler, names='value')\n",
        "dropdown_year.observe(DropdownYearEventhandler, names='value')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62SI2ukgXZ3c"
      },
      "source": [
        "display(dashboard)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3G9Tx_2XlDu"
      },
      "source": [
        "### References\n",
        "\n",
        "* https://github.com/huggingface/naacl_transfer_learning_tutorial\n",
        "* https://medium.com/swlh/transformer-fine-tuning-for-sentiment-analysis-c000da034bb5\n"
      ]
    }
  ]
}